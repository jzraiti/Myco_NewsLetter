{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just for testing the groq api locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading function\n"
     ]
    }
   ],
   "source": [
    "print('Loading function')\n",
    "\n",
    "#openai client\n",
    "with open (\"./secrets/apiKey_groq.txt\", \"r\") as f:\n",
    "    key = f.read()\n",
    "\n",
    "groq_client = Groq(\n",
    "    api_key=key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as efficient language models or lightweight language models, have gained significant attention in recent years due to their importance in various natural language processing (NLP) applications. Here are some reasons why fast language models are crucial:\n",
      "\n",
      "1. **Computational Efficiency**: Fast language models are designed to be computationally efficient, which is essential for large-scale NLP applications where computational resources are limited. These models can process large amounts of text data quickly, making them ideal for tasks such as text classification, sentiment analysis, and language translation.\n",
      "2. **Scalability**: Fast language models can handle large datasets and process massive amounts of text data, making them scalable for big data applications. This property is particularly important for industries like customer service, where massive amounts of user feedback need to be analyzed quickly.\n",
      "3. **Real-time Processing**: Fast language models enable real-time processing of natural language input, which is critical for applications like chatbots, voice assistants, and social media analysis. This reduces the latency between user input and processing, enhancing user experience and enabling more accurate responses.\n",
      "4. **Edge Computing**: Fast language models can be deployed on edge devices, such as smartphones or smart home devices, allowing for real-time processing and compression of data at the device level. This reduces the need for data transmission and minimizes latency.\n",
      "5. **Memory Efficiency**: Fast language models use less memory than traditional language models, making them suitable for devices with limited memory or computation resources. This property is particularly important for mobile devices or embedded systems.\n",
      "6. **Low Latency for Time-Critical Applications**: Fast language models can process text data quickly, making them suitable for time-critical applications like emergency response systems, where timely analysis is crucial.\n",
      "7. **Improved User Experience**: By providing fast and accurate language processing capabilities, fast language models can improve the overall user experience in various applications, such as:\n",
      "\t* Sentiment analysis: Enables more accurate sentiment analysis, leading to better customer service.\n",
      "\t* Language translation: Facilitates faster and more accurate language translation, improving global communication.\n",
      "\t* Text summarization: Provides concise and accurate summaries of large text documents, reducing information overload.\n",
      "8. **Enabling New Applications**: Fast language models can enable new applications that were previously impossible or impractical due to computational limitations. For example, fast language models can be used for real-time speech recognition, music recommendations, or medical diagnosis.\n",
      "9. **Cost-Effective**: Fast language models can reduce computation costs by processing data more efficiently, making them a cost-effective solution for large-scale NLP applications.\n",
      "10. **Research and Development**: Fast language models offer opportunities for researchers to explore new algorithms, architectures, and data structures, leading to advancements in NLP and AI.\n",
      "\n",
      "In summary, fast language models are essential for scalable, real-time, and efficient NLP applications. They enable quick processing of large text datasets, reduce latency, and improve user experience, making them a critical component of modern AI and NLP systems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "chat_completion = groq_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MycoNewsletter3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
